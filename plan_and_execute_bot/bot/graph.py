"""LangGraph wrapper that glues planner, executor and re-planner."""
from typing import List
from langgraph.graph import StateGraph, END
from .schemas import PlanExecute, Response, Plan, Act
from .planner import make_plan
from .executor import agent_executor
from .prompts import REPLANNER_PROMPT
from .config import LLM_PLANNER  # we reuse the planner LLM for replanning
from .memory import memory

# ---------- State transition helpers ---------- #

async def plan_step(state: PlanExecute):
    print("游댃 [DEBUG] Iniciando plan_step...")
    print(f"游댃 [DEBUG] Input recibido: {state['input']}")
    
    # Obtener session_id del estado
    session_id = state.get("session_id")
    
    # Crear plan con contexto de conversaci칩n
    plan = make_plan(state["input"], session_id)
    print(f"游댃 [DEBUG] Plan generado: {plan.steps}")
    
    # Inicializar conversation_history si no existe
    conversation_history = state.get("conversation_history", [])
    
    return {
        "plan": plan.steps,
        "conversation_history": conversation_history
    }

async def execute_step(state: PlanExecute):
    print("游댃 [DEBUG] Iniciando execute_step...")
    plan = state["plan"]
    past_steps = state.get("past_steps", [])
    
    print(f"游댃 [DEBUG] Plan actual: {plan}")
    print(f"游댃 [DEBUG] Pasos completados: {len(past_steps)}")
    
    if not plan:
        print("游댃 [DEBUG] No hay m치s pasos en el plan")
        return {"response": "Plan completado, pero no se pudo obtener una respuesta final."}
    
    # Detectar bucles - si hemos ejecutado la misma tarea m치s de 2 veces
    task = plan[0]
    task_count = sum(1 for step, _ in past_steps if step == task)
    if task_count >= 2:
        print(f"游댃 [DEBUG] Detectado bucle en la tarea: {task}")
        return {"response": f"No se pudo completar la tarea '{task}' despu칠s de m칰ltiples intentos. Por favor, reformula tu consulta."}
    
    plan_str = "\n".join(f"{i+1}. {step}" for i, step in enumerate(plan))
    print(f"游댃 [DEBUG] Ejecutando tarea: {task}")
    
    # Incluir contexto de conversaci칩n en la tarea si est치 disponible
    session_id = state.get("session_id")
    context_info = ""
    if session_id:
        context = memory.get_context_for_planning(session_id, max_messages=5)
        if context != "Esta es una nueva conversaci칩n.":
            context_info = f"\n\nContexto de conversaci칩n:\n{context}"
    
    task_formatted = f"""For the following plan:
        {plan_str}\n\nYou are tasked with executing step 1, {task}.{context_info}"""
    print(f"游댃 [DEBUG] Tarea formateada: {task_formatted}")
    print("游댃 [DEBUG] Invocando agent_executor...")
    
    try:
        agent_response = await agent_executor.ainvoke(
            {"input": task_formatted}
        )
        print(f"游댃 [DEBUG] Respuesta del agente: {agent_response}")
        
        # Agregar el paso completado a past_steps
        new_past_steps = past_steps + [(task, agent_response["output"])]
        
        # Remover el primer paso del plan (ya ejecutado)
        remaining_plan = plan[1:] if len(plan) > 1 else []
        
        result = {
            "past_steps": new_past_steps,
            "plan": remaining_plan
        }
        print(f"游댃 [DEBUG] Resultado de execute_step: {result}")
        return result
        
    except Exception as e:
        print(f"游댃 [DEBUG] Error en execute_step: {e}")
        return {"response": f"Error ejecutando la tarea: {str(e)}"}

async def replan_or_finish(state: PlanExecute):
    """Decide whether to finish or continue."""
    print("游댃 [DEBUG] Iniciando replan_or_finish...")
    print(f"游댃 [DEBUG] Estado actual: {state}")
    
    plan = state.get("plan", [])
    past_steps = state.get("past_steps", [])
    session_id = state.get("session_id")
    
    # Si no hay m치s pasos en el plan, intentar generar una respuesta final
    if not plan:
        print("游댃 [DEBUG] No hay m치s pasos, generando respuesta final...")
        if past_steps:
            last_step_result = past_steps[-1][1]
            # Si el 칰ltimo resultado parece ser una respuesta final, usarla
            if any(keyword in last_step_result.lower() for keyword in ["춿c", "clima", "weather", "temperatura", "madrid", "barcelona"]):
                # Guardar la respuesta en memoria si hay sesi칩n activa
                if session_id:
                    memory.add_message(session_id, "assistant", last_step_result)
                return {"response": last_step_result}
        
        # Si no hay pasos anteriores 칰tiles, generar respuesta gen칠rica
        response = "He completado las tareas disponibles, pero no pude obtener la informaci칩n solicitada."
        if session_id:
            memory.add_message(session_id, "assistant", response)
        return {"response": response}
    
    plan_str = "\n".join(f"{i+1}. {s}" for i, s in enumerate(plan))
    past = "\n".join(f"{t} --> {r}" for t, r in past_steps)
    print(f"游댃 [DEBUG] Plan string: {plan_str}")
    print(f"游댃 [DEBUG] Past steps: {past}")
    
    # Limitar el n칰mero de pasos para evitar bucles infinitos
    if len(past_steps) >= 5:
        print("游댃 [DEBUG] Demasiados pasos ejecutados, finalizando...")
        if past_steps:
            last_result = past_steps[-1][1]
            response = f"Proceso completado. 칔ltimo resultado: {last_result}"
        else:
            response = "Proceso completado despu칠s de m칰ltiples pasos."
        
        if session_id:
            memory.add_message(session_id, "assistant", response)
        return {"response": response}
    
    # Incluir contexto de conversaci칩n en el replanning
    input_with_context = state["input"]
    if session_id:
        context = memory.get_context_for_planning(session_id, max_messages=5)
        if context != "Esta es una nueva conversaci칩n.":
            input_with_context = f"{context}\n\nConsulta actual: {state['input']}"
    
    prompt_chain = REPLANNER_PROMPT | LLM_PLANNER
    print("游댃 [DEBUG] Invocando replanner...")
    
    try:
        reply = (await prompt_chain.ainvoke(
            {
                "input": input_with_context,
                "plan": plan_str or "None",
                "past_steps": past or "None",
            }
        )).content
        print(f"游댃 [DEBUG] Respuesta del replanner: {reply}")

        if reply.startswith("RESPONSE:"):
            response = reply[len("RESPONSE:"):].strip()
            result = {"response": response}
            print(f"游댃 [DEBUG] Finalizando con respuesta: {result}")
            
            # Guardar respuesta en memoria
            if session_id:
                memory.add_message(session_id, "assistant", response)
            
            return result
        elif reply.startswith("PLAN:"):
            steps_text = reply[len("PLAN:"):].strip()
            steps = [line.split(".", 1)[1].strip() for line in steps_text.splitlines()
                     if "." in line and line.split(".", 1)[1].strip()]
            if steps:
                result = {"plan": steps}
                print(f"游댃 [DEBUG] Nuevo plan: {result}")
                return result
            else:
                print("游댃 [DEBUG] Plan vac칤o, finalizando...")
                response = "No se pudo generar un plan v치lido para continuar."
                if session_id:
                    memory.add_message(session_id, "assistant", response)
                return {"response": response}
        else:
            # fallback: treat as final response
            response = reply.strip()
            result = {"response": response}
            print(f"游댃 [DEBUG] Fallback - respuesta final: {result}")
            
            # Guardar respuesta en memoria
            if session_id:
                memory.add_message(session_id, "assistant", response)
            
            return result
            
    except Exception as e:
        print(f"游댃 [DEBUG] Error en replanner: {e}")
        response = f"Error en el proceso de replanificaci칩n: {str(e)}"
        if session_id:
            memory.add_message(session_id, "assistant", response)
        return {"response": response}

def should_finish(state: PlanExecute):
    has_response = state.get("response") is not None
    has_plan = bool(state.get("plan", []))
    decision = END if has_response else "executor"
    print(f"游댃 [DEBUG] should_finish decision: {decision}")
    print(f"游댃 [DEBUG] Estado tiene respuesta: {has_response}")
    print(f"游댃 [DEBUG] Estado tiene plan: {has_plan}")
    return decision

# ---------- Graph builder ---------- #

def build_chatbot_graph():
    print("游댃 [DEBUG] Construyendo grafo del chatbot...")
    graph = StateGraph(PlanExecute)
    graph.add_node("planner", plan_step)
    graph.add_node("executor", execute_step)
    graph.add_node("replan", replan_or_finish)

    graph.set_entry_point("planner")
    graph.add_edge("planner", "executor")
    graph.add_edge("executor", "replan")
    graph.add_conditional_edges("replan", should_finish)

    compiled_graph = graph.compile()
    print("游댃 [DEBUG] Grafo compilado exitosamente!")
    return compiled_graph
